{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZgybIMXbpCl"
   },
   "source": [
    "## PyTorch on Cloud TPUs: Single Core Training AlexNet on Fashion MNIST \n",
    "\n",
    "This notebook trains the [AlexNet](https://arxiv.org/abs/1404.5997) network on the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) using PyTorch with a single Cloud TPU core. This will show you how to train your own networks on a single Cloud TPU core and highlight the differences between using one vs. many Cloud TPU cores.\n",
    "\n",
    "PyTorch can use Cloud TPU cores as devices with the PyTorch/XLA package. For more on PyTorch/XLA see its [Github](https://github.com/pytorch/xla) or its [documentation](http://pytorch.org/xla/). We also have a [\"Getting Started\"](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb) Colab notebook. Additional Colab notebooks, like this one, are available on the PyTorch/XLA Github.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxSMwPAIb5zI"
   },
   "source": [
    "### Installing PyTorch/XLA\n",
    "\n",
    "Run the following cell (or copy it into your own notebook!) to install PyTorch, Torchvision, and PyTorch/XLA. It will take a couple minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OApBOAe1fpH_"
   },
   "source": [
    "# !pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfSCdVlA8jFg"
   },
   "source": [
    "### If you're using GPU with this colab notebook, run the below commented code to install GPU compatible PyTorch wheel and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1Vfg-rH8bF4"
   },
   "source": [
    "#!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/117/torch_xla-2.0-cp39-cp39-linux_x86_64.whl --force-reinstall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPrij_iPfqTV"
   },
   "source": [
    "### Only run the below commented cell if you would like a nightly release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJZrkoejQhxK"
   },
   "source": [
    "# VERSION = \"1.13\"  #@param [\"1.13\", \"nightly\", \"20220315\"]  # or YYYYMMDD format\n",
    "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "# !python pytorch-xla-env-setup.py --version $VERSION\n",
    "# import os \n",
    "# os.environ['LD_LIBRARY_PATH']='/usr/local/lib'\n",
    "# !echo $LD_LIBRARY_PATH\n",
    "\n",
    "# !sudo ln -s /usr/local/lib/libmkl_intel_lp64.so /usr/local/lib/libmkl_intel_lp64.so.1\n",
    "# !sudo ln -s /usr/local/lib/libmkl_intel_thread.so /usr/local/lib/libmkl_intel_thread.so.1\n",
    "# !sudo ln -s /usr/local/lib/libmkl_core.so /usr/local/lib/libmkl_core.so.1\n",
    "\n",
    "# !ldconfig\n",
    "# !ldd /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3rCVMRazoeB",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use Colab Cloud TPU\n",
    "\n",
    "\n",
    "* On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
    "* The cell below makes sure you have access to a TPU on Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P6b3uqfzpDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHzziBW5AoZH"
   },
   "source": [
    "#### Installing PyTorch/XLA\n",
    "\n",
    "Run the following cell (or copy it into your own notebook!) to install PyTorch, Torchvision, and PyTorch/XLA. It will take a couple minutes to run.\n",
    "\n",
    "The PyTorch/XLA package lets PyTorch connect to Cloud TPUs. (It's named PyTorch/XLA, not PyTorch/TPU, because XLA is the name of the TPU compiler.) In particular, PyTorch/XLA makes TPU cores available as PyTorch devices. This lets PyTorch create and manipulate tensors on TPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OApBOAe1fpH_"
   },
   "outputs": [],
   "source": [
    "# !pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.13-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfSCdVlA8jFg"
   },
   "source": [
    "#### If you're using GPU with this colab notebook, run the below commented code to install GPU compatible PyTorch wheel and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J1Vfg-rH8bF4"
   },
   "outputs": [],
   "source": [
    "#!pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.13-cp38-cp38-linux_x86_64.whl --force-reinstall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPrij_iPfqTV"
   },
   "source": [
    "#### Only run the below commented cell if you would like a nightly release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vJZrkoejQhxK"
   },
   "outputs": [],
   "source": [
    "# VERSION = \"1.13\"  #@param [\"1.13\", \"nightly\", \"20220315\"]  # or YYYYMMDD format\n",
    "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "# !python pytorch-xla-env-setup.py --version $VERSION\n",
    "# import os \n",
    "# os.environ['LD_LIBRARY_PATH']='/usr/local/lib'\n",
    "# !echo $LD_LIBRARY_PATH\n",
    "\n",
    "# !sudo ln -s /usr/local/lib/libmkl_intel_lp64.so /usr/local/lib/libmkl_intel_lp64.so.1\n",
    "# !sudo ln -s /usr/local/lib/libmkl_intel_thread.so /usr/local/lib/libmkl_intel_thread.so.1\n",
    "# !sudo ln -s /usr/local/lib/libmkl_core.so /usr/local/lib/libmkl_core.so.1\n",
    "\n",
    "# !ldconfig\n",
    "# !ldd /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3rCVMRazoeB",
    "tags": []
   },
   "source": [
    "### Use Cloud TPU Node\n",
    "\n",
    "* If this notebook is run on the Vertex AI Workbecnh, then you need to [create a Cloud TPU Node](https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm#tpu-nodes) in advance.\n",
    "* The cell below makes sure you are connected to a Cloud TPU Node on GCP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TPU_NAME\"] = \"auv-tpu-node\"\n",
    "os.environ[\"TPU_IP_ADDRESS\"] = \"10.107.30.42\"\n",
    "os.environ[\"XRT_TPU_CONFIG\"] = f\"tpu_worker;0;{os.environ['TPU_IP_ADDRESS']}:8470\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3rCVMRazoeB",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use Cloud TPU VM\n",
    "\n",
    "* If this notebook is run inside the Cloud TPU VM, run the config below.\n",
    "* How to (create a Cloud TPU VM)[https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm#tpu-vms] in advance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
    "os.environ[\"TPU_NAME\"] = \"dummy\"\n",
    "os.environ[\"XRT_TPU_CONFIG\"]=\"localservice;0;localhost:51011\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_izjOUccDg4"
   },
   "source": [
    "### Dataset & Network\n",
    "\n",
    "In this notebook we'll train AlexNet on the Fashion MNIST dataset. Both are provided by the [Torchvision package](https://pytorch.org/docs/stable/torchvision/index.html).\n",
    "\n",
    "Before diving in, let's look at the Fashion MNIST dataset. The dataset has 10 classes, each represented by an integer index. The following cell creates a mapping from these indices to their corresponding human-readable strings, then downloads the Fashion MNIST training dataset from Torchvision. It may take a minute to run.\n",
    "\n",
    "Torchvision provides easy access to many datasets, including COCO, CIFAR, and Cityscapes. See its documentation for a complete list. \n",
    "\n",
    "The dataset is stored on the Colab VM in the `/tmp/fashionmnist` directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FkLA4MSlcNf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9afdaed90d4b29added7dcb15daa6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61afbcdd397f4d2382b26aeefbcc722e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade6b4da45564002835b31f1d532ee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b3e0b67a3645ef8485ff5017b58d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/fashionmnist/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloads the Fashion MNIST dataset using Torchvision\n",
    "# Note: This may take a minute.\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Maps integer class index to human-readable string describing the class\n",
    "class_map = {\n",
    "0 : \"t-shirt\",\n",
    "1 : \"trouser\",\n",
    "2 : \"pullover\",\n",
    "3 : \"dress\",\n",
    "4 : \"coat\",\n",
    "5 : \"sandal\",\n",
    "6 : \"shirt\",\n",
    "7 : \"sneaker\",\n",
    "8 : \"bag\",\n",
    "9 : \"ankle boot\"\n",
    "}\n",
    "\n",
    "# Downloads the Fashion MNIST dataset using Torchvision\n",
    "raw_dataset = datasets.FashionMNIST(\n",
    "  os.path.join(\"/tmp/fashionmnist\"),\n",
    "  train=True,\n",
    "  download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zRyIvDK6Z_xM"
   },
   "source": [
    "Now that we have the dataset, we can look at elements of it directly. Each element of raw_dataset is a tuple. The first element is a single channel greyscale 28x28 Python Image Library (PIL) image, and the second element is the example's class index. You can change the `img_index` in the following cell to visualize different examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40bWSY2_ZrO9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ankle boot\n"
     ]
    }
   ],
   "source": [
    "img_index = 0\n",
    "tup = raw_dataset[img_index]\n",
    "display(tup[0].resize((224, 224)))\n",
    "print(class_map[tup[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BzG5t8HbaMf"
   },
   "source": [
    "Now we'll create our AlexNet model and put it on a Cloud TPU core.\n",
    "\n",
    "Torchvision lets us download many model architectures, including VGG, ResNet, and MobileNet. See its documentation for a complete list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMMZxHoIk9n7"
   },
   "outputs": [],
   "source": [
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "\n",
    "# Creates AlexNet for 10 classes\n",
    "net = torchvision.models.alexnet(num_classes=10)\n",
    "\n",
    "# Acquires the default Cloud TPU core and moves the model to it\n",
    "device = xm.xla_device()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYB7dKkqfsiI"
   },
   "source": [
    "### Dataloaders\n",
    "\n",
    "Now that we have our dataset and network, let's look at how we'll transform and load the data. As we saw when looking at the Fashion MNIST dataset (above), the examples are 28x28 single channel greyscale PIL images. Torchvision networks, however, expect PyTorch tensors representing  normalized three channel RGB images that are at least 224x224. The following cell defines a conversion from the original examples to the PyTorch tensors our AlexNet requires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoTe3v5W881g"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# See https://pytorch.org/docs/stable/torchvision/models.html for normalization\n",
    "# Pre-trained TorchVision models expect RGB (3 x H x W) images\n",
    "# H and W should be >= 224\n",
    "# Loaded into [0, 1] and normalized as follows:\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_rgb = transforms.Lambda(lambda image: image.convert('RGB'))\n",
    "resize = transforms.Resize((224, 224))\n",
    "my_transform = transforms.Compose([resize, to_rgb, transforms.ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFTMqbNMgwWI"
   },
   "source": [
    "Now we can download train and test datasets using TorchVision and apply this transform to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsXFl-CFgtG9"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(\n",
    "  os.path.join(\"/tmp/fashionmnist\"),\n",
    "  train=True,\n",
    "  download=True,\n",
    "  transform=my_transform)\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "  os.path.join(\"/tmp/fashionmnist\"),\n",
    "  train=False,\n",
    "  download=True,\n",
    "  transform=my_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YV9nMJRSh_ld"
   },
   "source": [
    "PyTorch provides a variety of \"Samplers\" to acquire elements of datasets in different orders. The [Random Sampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler), which we'll use, samples elements randomly without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khRAFXTe-KfX"
   },
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.RandomSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dy1Eq2O_iagC"
   },
   "source": [
    "Finally, we create DataLoaders that load batches of examples from our Dataset according to our Sampler's policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TV5yqz2W9PzX"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=batch_size,\n",
    "  sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_dataset,\n",
    "  batch_size=batch_size,\n",
    "  sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHQbrK5ijXGS"
   },
   "source": [
    "### Evaluating the Network\n",
    "\n",
    "Before training we want to verify our data->network pipeline and set a baseline level of performance. The following cell defines a function, `eval_network,` that runs a network on a dataset and shows the percentage of the dataset that was correctly classified as well as a sample batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlSLfLaW_A3G"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_9486/3478821455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt_to_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from google.colab import widgets\n",
    "\n",
    "t_to_img = transforms.Compose([transforms.ToPILImage(), transforms.Grayscale()])\n",
    "\n",
    "# Runs the given net on the batches provided by the test_loader\n",
    "# Records the number of correct predictions (guesses) and \n",
    "# prints the percentage of correct guesses on the dataset, plus a \n",
    "# sample batch.\n",
    "def eval_network(net, test_loader):\n",
    "  start_time = time.time()\n",
    "  num_correct = 0\n",
    "  total_guesses = 0\n",
    "\n",
    "  # Sets eval and no grad context for evaluation\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for data, targets in iter(test_loader):\n",
    "      # Sends data and targets to device\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # Acquires the network's best guesses at each class\n",
    "      results = net(data)\n",
    "      best_guesses = torch.argmax(results, 1)\n",
    "\n",
    "      # Updates number of correct and total guesses\n",
    "      num_correct += torch.eq(targets, best_guesses).sum().item()\n",
    "      total_guesses += batch_size\n",
    "    \n",
    "    # Prints output\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Correctly guessed \", num_correct/total_guesses*100, \"% of the dataset\")\n",
    "    print(\"Evaluated in \", elapsed_time, \" seconds\")\n",
    "    print(\"Sample batch:\")\n",
    "    \n",
    "    # Uses last batch as sample\n",
    "    grid = widgets.Grid(2, 4)\n",
    "    row = 0\n",
    "    col = 0\n",
    "    for ex in zip(data, targets, best_guesses):\n",
    "      data = ex[0].cpu()\n",
    "      target = class_map[ex[1].item()]\n",
    "      guess = class_map[ex[2].item()]\n",
    "\n",
    "      img = t_to_img(data)\n",
    "\n",
    "      with grid.output_to(row, col):\n",
    "        display(img)\n",
    "        print(\"Target: \", target)\n",
    "        print(\"Guess: \", guess)\n",
    "\n",
    "        # Updates grid location\n",
    "        if col == 3:\n",
    "          row += 1\n",
    "          col = 0\n",
    "        else:\n",
    "          col += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyXjocsog0We"
   },
   "outputs": [],
   "source": [
    "# Percentage of guesses that are correct (expected to be 0.1)\n",
    "eval_network(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qencz3bJpaNU"
   },
   "source": [
    "You should see the untrained network guess about 10% of the dataset correctly, since it's randomly guessing and there are 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJFsnpfxf0j2"
   },
   "source": [
    "### Training the Network\n",
    "\n",
    "Randomly guessing at what we're seeing isn't very interesting, so it's time to train our network.\n",
    "\n",
    "Basic training in PyTorch:\n",
    "\n",
    "- enumerates a dataset in batches\n",
    "- runs the network on each batch\n",
    "- evaluates the network's performance using a loss function\n",
    "- calls `backward()` to propagate gradients through the network\n",
    "- uses an optimizer to `step()` and apply the gradients to the network's weights\n",
    "\n",
    "In this case we'll use the [CrossEntropyLoss](https://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss) since we have a classification problem and AlexNet returns unnormalized scores for each class. We'll also use the [Adam](https://pytorch.org/docs/master/optim.html#torch.optim.Adam) optimizer since it's a popular optimizer.\n",
    "\n",
    "We'll only train for a single epoch for timeliness. The following cell should take 4-5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSl2WMQMGutS"
   },
   "outputs": [],
   "source": [
    "# Note: this will take 5-10 minutes to run.\n",
    "num_epochs = 1\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "# Ensures network is in train mode\n",
    "net.train()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "  for data, targets in iter(train_loader):\n",
    "    # Sends data and targets to device\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Acquires the network's best guesses at each class\n",
    "    results = net(data)\n",
    "\n",
    "    # Computes loss\n",
    "    loss = loss_fn(results, targets)\n",
    "\n",
    "    # Updates model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    xm.optimizer_step(optimizer, barrier=True)  # Note: Cloud TPU-specific code!\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"Spent \", elapsed_time, \" seconds training for \", num_epochs, \" epoch(s) on a single core.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "id8KQMotr3DA"
   },
   "source": [
    "\n",
    "So far we've just used Cloud TPU cores as devices, like any other PyTorch device. In the above training loop we see our first Cloud TPU-specific line of code: `xm.optimizer_step(optimizer, barrier=True).` \n",
    "\n",
    "PyTorch uses Cloud TPUs through the [XLA deep learning compiler](https://www.tensorflow.org/xla). This compiler records the operations we perform into a graph which is evaluated all-at-once and as needed. `xm.optimizer_step(optimizer, barrier=True)` inserts a \"barrier\" in the graph that forces evaluation every time the gradients are updated. This prevents XLA's graphs from growing too large. For more details about how PyTorch uses XLA and Cloud TPUs see [the documentation](http://pytorch.org/xla/).\n",
    "\n",
    "\n",
    "We can now re-evaluate our network's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KA_74FcEZ5cq"
   },
   "outputs": [],
   "source": [
    "eval_network(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHSM9PGcsdfd"
   },
   "source": [
    "You should see the network dramatically improve (it should guess 60%+)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl8iYcWxgJUv"
   },
   "source": [
    "### What's Next\n",
    "\n",
    "This Colab showed how to train AlexNet on the Fashion MNIST dataset using a single Cloud TPU core. Using a Cloud TPU core as a device required one tweak to our network: instead of calling `optimizer.step()` we called `optimizer_step(optimizer, barrier=True).` In future Colabs we'll see a few other tweaks that will let us maximize PyTorch's performance on Cloud TPUs. The [documentation](http://pytorch.org/xla/) also describes them. \n",
    "\n",
    "Additional information about PyTorch on Cloud TPUs, including more sample Colabs, is available on the PyTorch/XLA package's [Github](https://github.com/pytorch/xla). You're encouraged to try PyTorch on Cloud TPUs on both Colab and Google Cloud Platform, too! For Colab, just copy the first code cell in this notebook to start your own. If you have ideas/suggestions/comments the best way to contact the team is with an [issue on our Github](https://github.com/pytorch/xla/issues). "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PyTorch on Cloud TPUs: Single Core Training AlexNet on Fashion MNIST",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m106"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
